{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvq+QiO4HTH5hzyhbaz3sJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chayan009185/Python-basics-/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcRl8mIBZkxm"
      },
      "outputs": [],
      "source": [
        "# Assignments Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A parameter is a value that a machine learning model learns from the training data, such as the weights and biases in a neural network.\n",
        "\n",
        "\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "Correlation measures the strength and direction of the relationship between two variables.\n",
        "\n",
        "\n",
        "What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that as one variable increases, the other decreases (e.g., temperature and demand for warm clothing).\n",
        "\n",
        "\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning is a field of AI that enables computers to learn from data without being explicitly programmed.\n",
        "\n",
        "Main Components: Data, Features, Model, Loss Function, Optimizer, and Evaluation Metrics.\n",
        "\n",
        "\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "A lower loss value indicates a better model, as it represents the difference between predicted and actual values.\n",
        "\n",
        "\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: Numeric values with infinite possibilities (e.g., height, weight).\n",
        "\n",
        "Categorical variables: Distinct categories (e.g., colors, gender).\n",
        "\n",
        "\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Common techniques include One-Hot Encoding, Label Encoding, and Ordinal Encoding.\n",
        "\n",
        "\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "The dataset is divided into training (to train the model) and testing (to evaluate the model's performance).\n",
        "\n",
        "\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "A module in scikit-learn that provides utilities for feature scaling, encoding categorical variables, and transforming data.\n",
        "\n",
        "\n",
        "\n",
        "9. What is a Test set?\n",
        "\n",
        "A portion of the dataset used to evaluate the model's performance after training.\n",
        "\n",
        "\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        " In Python, you can split data into training and testing sets using the `train_test_split` function from the `sklearn.model_selection` module (part of the **scikit-learn** library). This is a common practice in machine learning to evaluate model performance."
      ],
      "metadata": {
        "id": "OxhwKFBYZ7Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example data (X: features, y: target)\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8]]  # Features\n",
        "y = [0, 1, 0, 1]                       # Target labels\n",
        "\n",
        "# Split data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,       # 30% for testing (can also use `train_size=0.7`)\n",
        "    random_state=42,     # Ensures reproducibility\n",
        "    shuffle=True,        # Shuffle data before splitting (default)\n",
        "    stratify=y           # Preserve class distribution (for classification)\n",
        ")\n",
        "\n",
        "print(\"Training features:\", X_train)\n",
        "print(\"Testing features:\", X_test)\n",
        "print(\"Training labels:\", y_train)\n",
        "print(\"Testing labels:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJZl0yUNbrgv",
        "outputId": "a43252c4-7bae-4b3f-b3a3-53ba38b24443"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features: [[3, 4], [5, 6]]\n",
            "Testing features: [[7, 8], [1, 2]]\n",
            "Training labels: [1, 0]\n",
            "Testing labels: [1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "Steps: Define the problem, Collect data, Perform EDA, Preprocess data, Select a model, Train, Evaluate, and Improve.\n",
        "\n",
        "\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps understand data distributions, relationships, and potential data quality issues.\n",
        "\n",
        "\n",
        "\n",
        "12. What is correlation?\n",
        "\n",
        "--Correlation measures the strength and direction of the relationship between two variables.\n",
        "\n",
        "\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "\n",
        "A **negative correlation** means that as one variable increases, the other variable tends to decrease (and vice versa). In other words, the two variables move in **opposite directions**.  \n",
        "\n",
        "- **Negative Correlation Coefficient (r):**  \n",
        "  - The strength of the correlation is measured by the **correlation coefficient (r)**, which ranges from **-1 to 1**.  \n",
        "  - A value **close to -1** indicates a **strong negative correlation**.  \n",
        "  - A value **close to 0** means **no correlation**.  \n",
        "\n",
        "\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "\n",
        "Using pandas:\n",
        "\n",
        "import pandas as pd\n",
        "df.corr()\n",
        "\n",
        "\n",
        "\n",
        "15. What is causation? Explain the difference between correlation and causation with an example.\n",
        "\n",
        "Causation: One event directly influences another.\n",
        "\n",
        "Difference: Correlation shows association, while causation indicates a cause-effect relationship.\n",
        "\n",
        "Example: Ice cream sales and drowning incidents correlate, but eating ice cream doesnâ€™t cause drowning (temperature is the cause).\n",
        "\n",
        "\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "Optimizer: Algorithm that adjusts model parameters to minimize the loss function.\n",
        "\n",
        "Types:\n",
        "\n",
        "SGD (Stochastic Gradient Descent): Updates parameters using a small batch of data.\n",
        "\n",
        "Adam (Adaptive Moment Estimation): Combines momentum and adaptive learning rate.\n",
        "\n",
        "RMSprop: Adjusts learning rates dynamically for better convergence.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "17. What is sklearn.linear_model?\n",
        "\n",
        "A module in scikit-learn for linear regression models like LinearRegression() and LogisticRegression().\n",
        "\n",
        "\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "Trains the model using training data.\n",
        "\n",
        "Arguments: X_train, y_train (features and labels).\n",
        "\n",
        "\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "Predicts outcomes for new input data.\n",
        "\n",
        "Argument: X_test (feature data).\n",
        "\n",
        "\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "\n",
        "--Continuous variables: Numeric values with infinite possibilities (e.g., height, weight).\n",
        "\n",
        "Categorical variables: Distinct categories (e.g., colors, gender).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling transforms features to a similar scale, improving model convergence.\n",
        "\n",
        "Methods: Normalization, Standardization.\n",
        "\n",
        "\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "\n",
        "Using StandardScaler:"
      ],
      "metadata": {
        "id": "JiIY2ooTcJRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "OrQW53mucQ5z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "-A module in scikit-learn that provides utilities for feature scaling, encoding categorical variables, and transforming data.\n",
        "\n",
        "\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "In Python, you can split data into training and testing sets using the `train_test_split` function from the `sklearn.model_selection` module (part of the **scikit-learn** library). This is a common practice in machine learning to evaluate model performance."
      ],
      "metadata": {
        "id": "KJBcrdzDcUQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example data (X: features, y: target)\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8]]  # Features\n",
        "y = [0, 1, 0, 1]                       # Target labels\n",
        "\n",
        "# Split data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,       # 30% for testing (can also use `train_size=0.7`)\n",
        "    random_state=42,     # Ensures reproducibility\n",
        "    shuffle=True,        # Shuffle data before splitting (default)\n",
        "    stratify=y           # Preserve class distribution (for classification)\n",
        ")\n",
        "\n",
        "print(\"Training features:\", X_train)\n",
        "print(\"Testing features:\", X_test)\n",
        "print(\"Training labels:\", y_train)\n",
        "print(\"Testing labels:\", y_test)"
      ],
      "metadata": {
        "id": "5CIet3oQdwBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding.\n",
        "\n",
        "\n",
        "Data encoding is the process of converting categorical (non-numeric) data into a numerical format that machine learning models can understand. Since most algorithms (like linear regression, neural networks, etc.) work with numbers, categorical variables (e.g., colors, countries, yes/no responses) must be transformed before training.\n",
        "\n",
        "\n",
        "## Common Types of Data Encoding\n",
        "\n",
        "### 1. Label Encoding (Ordinal Encoding)\n",
        "- Assigns a unique integer to each category.\n",
        "- Suitable for **ordinal data** (categories with a meaningful order)."
      ],
      "metadata": {
        "id": "OE0d5pJAdxmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = [\"Low\", \"Medium\", \"High\", \"Low\", \"High\"]\n",
        "encoder = LabelEncoder()\n",
        "encoded_data = encoder.fit_transform(data)\n",
        "\n",
        "print(encoded_data)  # Output: [1, 2, 0, 1, 0]"
      ],
      "metadata": {
        "id": "91LKkrM7ewBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. One-Hot Encoding (Nominal Data)**\n",
        "- Creates binary (0/1) columns for each category.\n",
        "- Used for **nominal data** (no inherent order)."
      ],
      "metadata": {
        "id": "6yB76wvqe4S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame({\"Fruit\": [\"Apple\", \"Banana\", \"Orange\", \"Apple\"]})\n",
        "one_hot_encoded = pd.get_dummies(data, columns=[\"Fruit\"])\n",
        "\n",
        "print(one_hot_encoded)"
      ],
      "metadata": {
        "id": "niuN-Ua4e6HW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}